{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seasonal-somalia",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [5]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "emotional-boring",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T09:53:36.033486Z",
     "iopub.status.busy": "2021-02-25T09:53:36.029170Z",
     "iopub.status.idle": "2021-02-25T09:53:37.957012Z",
     "shell.execute_reply": "2021-02-25T09:53:37.956489Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 1.946811,
     "end_time": "2021-02-25T09:53:37.957151",
     "exception": false,
     "start_time": "2021-02-25T09:53:36.010340",
     "status": "completed"
    },
    "tags": [],
    "title": "setup"
   },
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "from IPython.core.display import display\n",
    "from typing_extensions import runtime\n",
    "import numpy as np\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')\n",
    "get_ipython().run_line_magic('run', 'setup')\n",
    "\n",
    "# sorteert de kolommen alfabetisch, is makkelijker visueel te debuggen.\n",
    "def sortcolumns(df):\n",
    "  return df[sorted(df.columns)]\n",
    "\n",
    "# prepareer een RIVM dataset\n",
    "def prepare(dataset, day=0):\n",
    "  df = RIVM.csv(dataset, day)\n",
    "  # hernoem kolommen voor makkelijker uniforme data bewerking\n",
    "  for old, new in [('Municipality_code', 'GemeenteCode'), ('Security_region_code', 'VeiligheidsregioCode'), ('Security_region_name', 'Veiligheidsregio')]:\n",
    "    if old in df:\n",
    "      df[new] = df[old]\n",
    "  if 'GemeenteCode' in df:\n",
    "    df['GemeenteCode'] = df['GemeenteCode'].fillna('GM0000')\n",
    "\n",
    "  if 'Agegroup' in df:\n",
    "    df['LeeftijdCode'] = 'LE' + df['Agegroup'].replace({'0-9': '00-09', '<50': '00-00', 'Unknown': '00-00', 'Onbekend': '00-00'}).replace('-', '', regex=True).astype(str)\n",
    "    df['Total_reported'] = 1 # impliciet in casus-landelijk\n",
    "    df = df.replace({'Hospital_admission': {'Yes': 1, 'No': 0, 'Unknown': 0}, 'Deceased': {'Yes': 1, 'No': 0, 'Unknown': 0}})\n",
    "\n",
    "  # voeg regiocodes to aan elke regel in de dataset\n",
    "  if 'GemeenteCode' in df:\n",
    "    for regiotype in ['GGDregio', 'Provincie', 'Landsdeel', 'Schoolregio']:\n",
    "      df = df.merge(gemeenten[['GemeenteCode', f'{regiotype}Code']].drop_duplicates(), on='GemeenteCode')\n",
    "\n",
    "  # als er geen gemeentecode is, maar misschien wel een VR code, vervang die door VR00\n",
    "  if 'GemeenteCode' in df and 'VeiligheidsregioCode' in df:\n",
    "    df.loc[df.GemeenteCode == 'GM0000', 'VeiligheidsregioCode'] = 'VR00'\n",
    "    df.loc[df.GemeenteCode == 'GM0000', 'Veiligheidsregio'] = ''\n",
    "\n",
    "  df['LandCode'] = 'NL'\n",
    "  df['Land'] = 'Nederland'\n",
    "\n",
    "  # knip de tijd van de datum af, en stop hem in 'Today' (referentiepunt metingen)\n",
    "  if 'Date_of_report' in df:\n",
    "    df['Datum'] = df.Date_of_report.str.replace(' .*', '', regex=True)\n",
    "  elif 'Date_file' in df:\n",
    "    df['Datum'] = df.Date_file.str.replace(' .*', '', regex=True)\n",
    "  df['Today'] = pd.to_datetime(df.Datum)\n",
    "\n",
    "  # zet 'Date' naar de bij de betreffende dataset horende meetdatum-kolom\n",
    "  for when in ['Date_statistics', 'Date_of_statistics', 'Date_of_publication']:\n",
    "    if when in df:\n",
    "      df['Date'] = pd.to_datetime(df[when])\n",
    "      # en direct maar weken terug, die hebben we vaker nodig\n",
    "      df['WekenTerug'] = ((df.Today - df.Date) / np.timedelta64(7, 'D')).astype(int)\n",
    "\n",
    "  return sortcolumns(df).sort_values(by=['Date'])\n",
    "\n",
    "async def publish(df, objectName):\n",
    "  #df2 = df.set_index('Code')\n",
    "  m = (df == np.inf)\n",
    "  df2 = df.loc[m.any(axis=1), m.any(axis=0)]\n",
    "  display(df2.head())\n",
    "\n",
    "  os.makedirs('artifacts', exist_ok = True)\n",
    "  df.to_csv(f'artifacts/{objectName}.csv', index=True)\n",
    "\n",
    "  if knack:\n",
    "    print('updating knack')\n",
    "    if await knack.update(objectName=objectName, df=df, slack=Munch(msg='\\n'.join(Cache.actions), emoji=None)) != False:\n",
    "      await knack.timestamps(objectName, Cache.timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conservative-workplace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T09:53:38.136125Z",
     "iopub.status.busy": "2021-02-25T09:53:38.134931Z",
     "iopub.status.idle": "2021-02-25T09:53:58.021540Z",
     "shell.execute_reply": "2021-02-25T09:53:58.021050Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 20.031963,
     "end_time": "2021-02-25T09:53:58.021675",
     "exception": false,
     "start_time": "2021-02-25T09:53:37.989712",
     "status": "completed"
    },
    "tags": [],
    "title": "regio: load regios en hun basisgegevens"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rivm/COVID-19_aantallen_gemeente_per_dag-2021-02-24@14-15.csv exists\n",
      "loading rivm/COVID-19_aantallen_gemeente_per_dag-2021-02-24@14-15.csv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rivm/COVID-19_ziekenhuisopnames-2021-02-24@14-15.csv exists\n",
      "loading rivm/COVID-19_ziekenhuisopnames-2021-02-24@14-15.csv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading rivm/COVID-19_ziekenhuisopnames-2021-02-23@14-15.csv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rivm/COVID-19_casus_landelijk-2021-02-24@14-15.csv exists\n",
      "loading rivm/COVID-19_casus_landelijk-2021-02-24@14-15.csv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading rivm/COVID-19_casus_landelijk-2021-02-23@14-15.csv.gz\n"
     ]
    }
   ],
   "source": [
    "@run\n",
    "def cell():\n",
    "  global gemeenten\n",
    "  # rename de kolommen naar \"Naam\" + \"NaamCode\" voor makkelijker uniforme data bewerking\n",
    "  gemeenten = pd.read_csv('gemeenten.csv').rename(columns={\n",
    "    'Code': 'GemeenteCode',\n",
    "    'Naam': 'Gemeente',\n",
    "    'Veiligheidsregio Code': 'VeiligheidsregioCode',\n",
    "    'GGD regio': 'GGDregio',\n",
    "    'Landcode': 'LandCode',\n",
    "  })\n",
    "  # niet nodig want die voegen we vanzelf toe bij de per-type constructie van de cijfers\n",
    "  del gemeenten['Type']\n",
    "  \n",
    "  global leeftijdsgroepen\n",
    "  leeftijdsgroepen = pd.read_csv('leeftijdsgroepen.csv')\n",
    "  del leeftijdsgroepen['Type']\n",
    "  lgb = CBS.bevolking(leeftijdsgroepen=True).reset_index()\n",
    "  lgb['Code'] = 'LE' + lgb['Range'].replace({'0-9': '00-09'}).replace('-', '', regex=True).astype(str)\n",
    "  lgb = lgb.rename(columns={'BevolkingOpDeEersteVanDeMaand': 'Personen'})\n",
    "  leeftijdsgroepen = leeftijdsgroepen.merge(lgb[['Code', 'Personen']], how='left', on='Code')\n",
    "\n",
    "  global regiocodes\n",
    "  regiocodes = pd.read_csv('regiocodes.csv')\n",
    "  # sluit aan bij de uniforme naamgeving van hierboven\n",
    "  regiocodes = regiocodes.rename(columns={'Landcode': 'LandCode'})\n",
    "  regiocodes.loc[regiocodes.Type == 'GGD', 'Type'] = 'GGDregio'\n",
    "  \n",
    "  # voeg de regiocodes toe aan de gemeenten tabel voor makkelijker uniforme data bewerking\n",
    "  for regiotype in ['GGDregio', 'Provincie', 'Landsdeel', 'Schoolregio']:\n",
    "    gemeenten = gemeenten.merge(\n",
    "      regiocodes[regiocodes.Type == regiotype][['LandCode', 'Regio', 'Code']].rename(columns={'Code': regiotype + 'Code', 'Regio': regiotype}),\n",
    "      how='left',\n",
    "      on=[regiotype, 'LandCode'],\n",
    "    )\n",
    "  gemeenten = gemeenten.merge(\n",
    "    regiocodes[regiocodes.Type == 'Land'][['LandCode', 'Regio']].rename(columns={'Regio': 'Land'}),\n",
    "    how='left',\n",
    "    on='LandCode'\n",
    "  )\n",
    "\n",
    "  # lege regel voor GM0000\n",
    "  for regiotype, prefix in [('GGDregio', 'GG'), ('Veiligheidsregio', 'VR'), ('Provincie', 'PV'), ('Landsdeel', 'LD'), ('Schoolregio', 'SR')]:\n",
    "    gemeenten.loc[gemeenten.GemeenteCode == 'GM0000', regiotype] = ''\n",
    "    gemeenten.loc[gemeenten.GemeenteCode == 'GM0000', f'{regiotype}Code'] = f'{prefix}00'\n",
    "  gemeenten.loc[gemeenten.GemeenteCode == 'GM0000', 'LandCode'] = 'NL'\n",
    "  \n",
    "  base = 'https://opendata.cbs.nl/ODataApi/OData/37230ned'\n",
    "  \n",
    "  # voor perioden pak de laatste\n",
    "  periode = CBS.odata(base + '/Perioden').iloc[[-1]]['Key'].values[0]\n",
    "  \n",
    "  # startsWith would have been better to do in the filter but then the CBS \"odata-ish\" server responds with\n",
    "  # \"Object reference not set to an instance of an object.\"\n",
    "  bevolking = CBS.odata(base + f\"/TypedDataSet?$filter=(Perioden eq '{periode}')&$select=RegioS, BevolkingAanHetBeginVanDePeriode_1\")\n",
    "  # want de CBS odata API snap startsWith niet...\n",
    "  bevolking = bevolking[bevolking.RegioS.str.startswith('GM')]\n",
    "  # die _1 betekent waarschijnlijk dat het gedrag ooit gewijzigd is en er een nieuwe \"versie\" van die kolom is gepubliceerd\n",
    "  bevolking.rename(columns={'RegioS': 'GemeenteCode', 'BevolkingAanHetBeginVanDePeriode_1': 'BevolkingAanHetBeginVanDePeriode'}, inplace=True)\n",
    "  \n",
    "  gemeenten = gemeenten.merge(bevolking, how='left', on='GemeenteCode')\n",
    "  # default naar gegeven waarde bij ontbrekende data\n",
    "  gemeenten.loc[gemeenten.Personen == 0, 'Personen'] = gemeenten.BevolkingAanHetBeginVanDePeriode\n",
    "  del gemeenten['BevolkingAanHetBeginVanDePeriode']\n",
    "  gemeenten = sortcolumns(gemeenten)\n",
    "\n",
    "  global aantallen, ziekenhuisopnames, ziekenhuisopnames_1, casus_landelijk, casus_landelijk_1\n",
    "  aantallen = prepare('COVID-19_aantallen_gemeente_per_dag', 0)\n",
    "  ziekenhuisopnames = prepare('COVID-19_ziekenhuisopnames', 0)\n",
    "  ziekenhuisopnames_1 = prepare('COVID-19_ziekenhuisopnames', 1)\n",
    "  casus_landelijk = prepare('COVID-19_casus_landelijk', 0)\n",
    "  casus_landelijk_1 = prepare('COVID-19_casus_landelijk', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sorted-colon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T09:53:58.078079Z",
     "iopub.status.busy": "2021-02-25T09:53:58.047540Z",
     "iopub.status.idle": "2021-02-25T09:53:58.097016Z",
     "shell.execute_reply": "2021-02-25T09:53:58.096559Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.068381,
     "end_time": "2021-02-25T09:53:58.097130",
     "exception": false,
     "start_time": "2021-02-25T09:53:58.028749",
     "status": "completed"
    },
    "tags": [],
    "title": "Ondersteunde code voor de regio berekeningen"
   },
   "outputs": [],
   "source": [
    "def groupregio(regiotype):\n",
    "  \"\"\"\n",
    "    Groepeer de gemeenten tabel op gegeven regiotypen en sommeer personen/oppervlakte\n",
    "  \"\"\"\n",
    "  global gemeenten\n",
    "\n",
    "  grouping = [ f'{regiotype}Code', regiotype]\n",
    "  if regiotype != 'Land':\n",
    "    grouping += [ 'LandCode' ]\n",
    "\n",
    "  # deze kolommen willen we voor de resultset, ook al zijn ze voor alles behalve 'Gemeente' leeg\n",
    "  columns = [\n",
    "    'GGDregio',\n",
    "    'Veiligheidsregio',\n",
    "    'VeiligheidsregioCode',\n",
    "    'Provincie',\n",
    "    'Landsdeel',\n",
    "    'Schoolregio',\n",
    "    'Land',\n",
    "  ]\n",
    "\n",
    "  if regiotype == 'Gemeente':\n",
    "    # hier hoeven we niets te doen dan de juiste kolommen te selecteren\n",
    "    df = gemeenten[grouping + columns + ['Personen', 'Opp land km2']].rename(columns={'Gemeente': 'Naam', 'GemeenteCode': 'Code'})\n",
    "  elif regiotype == 'Leeftijd':\n",
    "    df = (leeftijdsgroepen\n",
    "      # voeg de lege kolommen toe\n",
    "      .assign(**{ col: '' for col in columns})\n",
    "      .assign(**{'Opp land km2': 0})\n",
    "    )\n",
    "  else:\n",
    "    df = (gemeenten[gemeenten.GemeenteCode != 'GM0000']\n",
    "      # groupeer op regiotype, sommeer oppervlakte en personen\n",
    "      .groupby(grouping).agg({ 'Personen': 'sum', 'Opp land km2': 'sum' })\n",
    "      .reset_index()\n",
    "      # standardiseerd de 'Naam' en 'Code' kolommen zodat ze klaar zijn voor output.\n",
    "      .rename(columns={regiotype: 'Naam', f'{regiotype}Code': 'Code'})\n",
    "      # voeg de lege kolommen toe\n",
    "      .assign(**{ col: '' for col in columns })\n",
    "    )\n",
    "    if regiotype == 'Land':\n",
    "      df['Land'] = df['Naam']\n",
    "      df['LandCode'] = df['Code']\n",
    "  # voeg het regiotype toe in de Type kolom\n",
    "  return df.assign(Type=regiotype)\n",
    "\n",
    "def sumcols(df, regiotype, columns):\n",
    "  \"\"\"\n",
    "    groepeer en sommeer deceased/admission/positive\n",
    "  \"\"\"\n",
    "  regiotype_code = f'{regiotype}Code'\n",
    "  return (df\n",
    "    # groepeer op regiotype en selecteer de gewenste kolommen\n",
    "    .groupby([regiotype_code])[list(columns.keys())]\n",
    "    # sommeer\n",
    "    .sum()\n",
    "    # rename naar gewenste output kolommen\n",
    "    .rename(columns=columns)\n",
    "  )\n",
    "\n",
    "def histcols(df, regiotype, maxweeks, column, colors=False, highestweek=False):\n",
    "  \"\"\"\n",
    "    voeg week historie toe:\n",
    "    - regiotype\n",
    "    - maxweeks = hoeveel weken\n",
    "    - column = deceased/admission/positive naam => output kolom\n",
    "    - colors = toevoegen schaalverdeling kleuren\n",
    "    - highestweek = toevoegen op welke week het maximum was behaald\n",
    "  \"\"\"\n",
    "  # in principe zouden we kunnen groeperen/sommeren op meerdere kolommen tegelijk maar dan worden colors en highestweek weer heel complex\n",
    "  assert len(column) == 1\n",
    "  label = list(column.values())[0]\n",
    "  datacolumn = list(column.keys())[0]\n",
    "  regiotype_code = f'{regiotype}Code'\n",
    "\n",
    "  # knip alle data van >= maxweeks eruit\n",
    "  df = df[df.WekenTerug < maxweeks]\n",
    "\n",
    "  # als we schalen naar 100.000, voor hoeveel telt elke melding dan mee\n",
    "  if 'scale' in df:\n",
    "    df = df.assign(count=df[datacolumn] * df.scale).replace(np.inf, 0)\n",
    "  else:\n",
    "    df = df.assign(count=df[datacolumn])\n",
    "\n",
    "  df = (df\n",
    "    # groepeer op reguitype en wekenterug\n",
    "    .groupby([regiotype_code, 'WekenTerug'])['count']\n",
    "    # optellen (de aantallen zijn eventueel hierboven al geschaald)\n",
    "    .sum()\n",
    "    # maak de week nummers kolommen\n",
    "    .unstack(level=-1)\n",
    "    # en vul de kolommen uit zodat als een week helemaal geen meldingen heeft dat die niet weg blijft maar 0 bevat\n",
    "    .reindex(columns=np.arange(maxweeks), fill_value=0)\n",
    "  )\n",
    "\n",
    "  merges = []\n",
    "  # must be done before colors is merged and before the columns are renamed\n",
    "  if highestweek:\n",
    "    merges.append(df.idxmax(axis=1).to_frame().rename(columns={0: f'{label} hoogste week'}))\n",
    "\n",
    "  # hernoem de kolommen van de getallen die ze nu zijn\n",
    "  df.columns = [f'{label} w{-col}' for col in df.columns.values]\n",
    "\n",
    "  # must be done before highestweek is merged but after the columns are renamed\n",
    "  if colors:\n",
    "    # kleurkolommen zijn waarde van de week gedeeld door het maximum over de weken heen\n",
    "    merges.append((df.divide(df.max(axis=1), axis=0) * 1000).rename(columns={col:col.replace(' w', ' cw') for col in df}))\n",
    "\n",
    "  for extra in merges:\n",
    "    df = df.merge(extra, left_index=True, right_index=True)\n",
    "\n",
    "  # bij ontbreken van w-1 vaste waarde 9.99\n",
    "  df[f'{label} t.o.v. vorige week'] = (df[f'{label} w0'] / df[f'{label} w-1']).replace(np.inf, 9.99)\n",
    "  return df\n",
    "\n",
    "def collect(regiotype):\n",
    "  \"\"\"\n",
    "    verzamel alle kolommen voor gegeven regiotype\n",
    "  \"\"\"\n",
    "  regiotype_code = f'{regiotype}Code'\n",
    "\n",
    "  def datasets():\n",
    "    if regiotype == 'Leeftijd':\n",
    "      global casus_landelijk, casus_landelijk_1\n",
    "      return (casus_landelijk, casus_landelijk, casus_landelijk_1)\n",
    "    else:\n",
    "      global aantallen, ziekenhuisopnames, ziekenhuisopnames_1\n",
    "      return (aantallen, ziekenhuisopnames, ziekenhuisopnames_1)\n",
    "\n",
    "  aantallen, ziekenhuisopnames, ziekenhuisopnames_1 = datasets()\n",
    "\n",
    "  assert len(aantallen.Datum.unique()) == 1\n",
    "  assert len(ziekenhuisopnames_1.Datum.unique()) == 1\n",
    "  assert list(aantallen.Datum.unique()) == list(ziekenhuisopnames.Datum.unique()), list(aantallen.Datum.unique()) + list(ziekenhuisopnames.Datum.unique())\n",
    "\n",
    "  # sommeer Total_reported en Deceased voor gegeven regiotype\n",
    "  pos_dec = sumcols(aantallen, regiotype, {'Total_reported':'Positief getest', 'Deceased':'Overleden'})\n",
    "  # toename is precies hetzelfde maar dan alleen voor de metingen van 'vandaag'\n",
    "  pos_dec_delta = sumcols(\n",
    "    aantallen[aantallen.Date == aantallen.Today],\n",
    "    regiotype,\n",
    "    {'Total_reported':'Positief getest (toename)', 'Deceased':'Overleden (toename)'}\n",
    "  )\n",
    "  # sommeer Hospital_admission voor gegeven regiotype\n",
    "  admissions = sumcols(ziekenhuisopnames, regiotype, {'Hospital_admission':'Ziekenhuisopname'})\n",
    "  # sommeer Hospital_admission van 'vorige dag' voor gegeven regiotype\n",
    "  admissions_1 = sumcols(ziekenhuisopnames_1, regiotype, {'Hospital_admission':'Ziekenhuisopname_1'})\n",
    "  # voeg ze bij elkaar en trek ze van elkaar af\n",
    "  admissions_delta = admissions.merge(admissions_1, how='left', on=regiotype_code)\n",
    "  admissions_delta['Ziekenhuisopname (toename)'] = admissions_delta.Ziekenhuisopname - admissions_delta.Ziekenhuisopname_1\n",
    "  # niet meer nodig en vervuilen anders het resultaat\n",
    "  del admissions_delta['Ziekenhuisopname']\n",
    "  del admissions_delta['Ziekenhuisopname_1']\n",
    "\n",
    "  # groupeer de gemeenten op gegeven regiotype\n",
    "  df = (groupregio(regiotype)\n",
    "    # en voeg de berekende kolommen toe\n",
    "    .merge(pos_dec, how='left', left_on='Code', right_index=True)\n",
    "    .merge(admissions, how='left', left_on='Code', right_index=True)\n",
    "    .merge(pos_dec_delta, how='left', left_on='Code', right_index=True)\n",
    "    .merge(admissions_delta, how='left', left_on='Code', right_index=True)\n",
    "    .fillna(0)\n",
    "  )\n",
    "  # per 100k voor de absolute kolommen\n",
    "  for cat in [pos_dec, admissions]:\n",
    "    for col in cat.columns:\n",
    "      df[col + ' per 100.000'] = ((df[col] * 100000) / df.Personen).replace(np.inf, 0)\n",
    "\n",
    "  df['Positief getest 1d/100k'] = ((df['Positief getest (toename)'] * 100000) / df.Personen).replace(np.inf, 0)\n",
    "  df['Positief getest percentage'] = (df['Positief getest'] / df.Personen).replace(np.inf, 0)\n",
    "  df['Positief getest per km2'] = (df['Positief getest'] / df['Opp land km2']).replace(np.inf, 0)\n",
    "\n",
    "  # weekhistories\n",
    "  maxweeks = 26\n",
    "  df = (df\n",
    "    .merge(histcols(\n",
    "      aantallen,\n",
    "      regiotype,\n",
    "      maxweeks=maxweeks,\n",
    "      colors=True,\n",
    "      highestweek=True,\n",
    "      column={'Total_reported':'Positief getest'}), how='left', left_on='Code', right_index=True)\n",
    "    .merge(histcols(\n",
    "      aantallen.merge(df.assign(scale=100000 / df.Personen)[['Code', 'scale']], left_on=regiotype_code, right_on='Code'),\n",
    "      regiotype,\n",
    "      maxweeks=maxweeks,\n",
    "      column={'Total_reported':'Positief getest 7d/100k'}), how='left', left_on='Code', right_index=True)\n",
    "    .merge(histcols(ziekenhuisopnames,\n",
    "      regiotype,\n",
    "      maxweeks=maxweeks,\n",
    "      colors=True,\n",
    "      column={'Hospital_admission':'Ziekenhuisopname'}), how='left', left_on='Code', right_index=True)\n",
    "    .merge(histcols(\n",
    "      aantallen,\n",
    "      regiotype,\n",
    "      maxweeks=maxweeks,\n",
    "      colors=True,\n",
    "      column={'Deceased':'Overleden'}), how='left', left_on='Code', right_index=True)\n",
    "  )\n",
    "  df['Datum'] = aantallen.Datum.unique()[0]\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "explicit-synthetic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T09:53:58.114424Z",
     "iopub.status.busy": "2021-02-25T09:53:58.113907Z",
     "iopub.status.idle": "2021-02-25T09:54:06.854719Z",
     "shell.execute_reply": "2021-02-25T09:54:06.854239Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 8.751174,
     "end_time": "2021-02-25T09:54:06.854853",
     "exception": false,
     "start_time": "2021-02-25T09:53:58.103679",
     "status": "completed"
    },
    "tags": [],
    "title": "regio: load verschillende aggregatie niveaus"
   },
   "outputs": [],
   "source": [
    "@run\n",
    "def cell():\n",
    "  global regios\n",
    "  # verzamel de data voor de gegeven regiotypes en plak ze onder elkaar\n",
    "  regios = pd.concat([\n",
    "    collect(regiotype)\n",
    "    for regiotype in\n",
    "    [\n",
    "      'Gemeente',\n",
    "      'GGDregio',\n",
    "      'Veiligheidsregio',\n",
    "      'Provincie',\n",
    "      'Landsdeel',\n",
    "      'Schoolregio',\n",
    "      'Land',\n",
    "      'Leeftijd',\n",
    "    ]\n",
    "  ])\n",
    "  # maak de kolommen leeg voor GM0000\n",
    "  # hernoem de eerder geuniformeerde kolomen terug naar de gewenste output\n",
    "  regios = regios.rename(columns={\n",
    "    'LandCode': 'Landcode',\n",
    "    'VeiligheidsregioCode': 'Veiligheidsregio Code',\n",
    "    'GGDregio': 'GGD regio'\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-significance",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepting-killer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T09:54:06.871881Z",
     "iopub.status.busy": "2021-02-25T09:54:06.871403Z",
     "iopub.status.idle": "2021-02-25T09:54:07.026908Z",
     "shell.execute_reply": "2021-02-25T09:54:07.025487Z"
    },
    "papermill": {
     "duration": 0.165243,
     "end_time": "2021-02-25T09:54:07.027160",
     "exception": true,
     "start_time": "2021-02-25T09:54:06.861917",
     "status": "failed"
    },
    "tags": [],
    "title": "load de gewenste kolom volgorde uit een file en publiceer"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'RegioV2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8b50ba84e053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RegioV2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RegioV2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RegioV2.csv'"
     ]
    }
   ],
   "source": [
    "order = pd.read_csv('RegioV2.csv')\n",
    "await publish(regios[order.columns.values].fillna(0), 'RegioV2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-accent",
   "metadata": {
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": [],
    "title": "Regioposten"
   },
   "outputs": [],
   "source": [
    "# just so the timestamps update OK\n",
    "Cache.reset()\n",
    "aantallen = prepare('COVID-19_aantallen_gemeente_per_dag')\n",
    "ziekenhuisopnames = prepare('COVID-19_ziekenhuisopnames')\n",
    "@run\n",
    "def cell():\n",
    "  import sys\n",
    "  global aantallen, ziekenhuisopnames\n",
    "  aantallen['Week'] = aantallen['Date'].dt.strftime('%Y-%V')\n",
    "  ziekenhuisopnames['Week'] = ziekenhuisopnames['Date'].dt.strftime('%Y-%V')\n",
    "\n",
    "  weken = list(pd.date_range(\n",
    "    start=min(aantallen.Date.min(), ziekenhuisopnames.Date.min()),\n",
    "    end=max(aantallen.Date.max(), ziekenhuisopnames.Date.max())\n",
    "  ).strftime('%Y-%V').unique())\n",
    "  print(len(weken), 'weken')\n",
    "\n",
    "  regiotypes = [ 'GGDregio', 'Gemeente', 'Land', 'Landsdeel', 'Provincie', 'Schoolregio', 'Veiligheidsregio' ]\n",
    "  for regiotype in regiotypes:\n",
    "    assert regiotype + 'Code' in aantallen, (regiotype, aantallen.columns)\n",
    "    assert regiotype + 'Code' in ziekenhuisopnames, (regiotype, ziekenhuisopnames.columns)\n",
    "\n",
    "  global regioposten\n",
    "  regioposten = []\n",
    "  for regiotype in regiotypes:\n",
    "    print(regiotype)\n",
    "    sys.stdout.flush()\n",
    "    code = regiotype + 'Code'\n",
    "\n",
    "    ag = sortcolumns(\n",
    "      aantallen[['Week', code, 'Date', 'Total_reported', 'Deceased']]\n",
    "      .assign(Hospital_admission=np.nan)\n",
    "    )\n",
    "    zo = sortcolumns(\n",
    "      ziekenhuisopnames[['Week', code, 'Date', 'Hospital_admission']]\n",
    "      .assign(Total_reported=np.nan, Deceased=np.nan)\n",
    "    )\n",
    "    df = (pd.concat([ag, zo], axis=0)\n",
    "      .sort_values(by=['Date'])\n",
    "      .groupby(['Week', code])\n",
    "      .agg({\n",
    "        'Date': [ 'max', 'nunique' ],\n",
    "        'Total_reported': [ 'sum', 'last' ],\n",
    "        'Deceased': [ 'sum', 'last' ],\n",
    "        'Hospital_admission': [ 'sum', 'last' ],\n",
    "      })\n",
    "      .reset_index()\n",
    "    )\n",
    "    df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "    df.rename(columns={\n",
    "      code: 'Code',\n",
    "      'Date max': 'Datum',\n",
    "      'Date nunique': 'Dagen',\n",
    "      'Total_reported sum': 'Positief getest week',\n",
    "      'Total_reported last': 'Positief getest laatste dag',\n",
    "      'Deceased sum': 'Overleden week',\n",
    "      'Deceased last': 'Overleden laatste dag',\n",
    "      'Hospital_admission sum': 'Ziekenhuisopname week',\n",
    "      'Hospital_admission last': 'Ziekenhuisopname laatste dag',\n",
    "    }, inplace=True)\n",
    "\n",
    "    regio = groupregio(regiotype)\n",
    "    regio = regio[[col for col in regio.columns if col == 'Code' or 'Code' not in col and 'km2' not in col]]\n",
    "    df = df.merge(regio, how='left', on='Code')\n",
    "    for col, coltype in zip(regio.columns, regio.dtypes):\n",
    "      if col == 'Personen':\n",
    "        df[col] = df[col].fillna(0).astype(int)\n",
    "      elif col == 'Type':\n",
    "        df[col] = df[col].fillna(regiotype)\n",
    "      elif coltype == np.float64:\n",
    "        df[col] = df[col].fillna(0)\n",
    "      elif coltype == object:\n",
    "        df[col] = df[col].fillna('')\n",
    "      else:\n",
    "        raise KeyError(col)\n",
    "    df['Landcode'] = 'NL'\n",
    "\n",
    "    base = [\n",
    "      (code, week)\n",
    "      for code in list(df.Code.unique())\n",
    "      for week in weken\n",
    "    ]\n",
    "    base = pd.DataFrame({\n",
    "        'Week': [week for code, week in base],\n",
    "        'Code': [code for code, week in base],\n",
    "      },\n",
    "      index=['-'.join(codeweek) for codeweek in base]\n",
    "    )\n",
    "\n",
    "    df['Key'] = df['Code'] + '-' + df['Week']\n",
    "    df.set_index('Key', inplace=True)\n",
    "    df.drop(columns=['Code', 'Week'], inplace=True)\n",
    "\n",
    "    df = base.join(df)\n",
    "\n",
    "    for col in ['Positief getest', 'Overleden', 'Ziekenhuisopname']:\n",
    "      # vul missende waarden met 0 vanaf de eerstgevonden waarde zodat cumsum goed werkt\n",
    "      df[f'{col} week'] = df[f'{col} week'].mask(df[f'{col} week'].ffill().isnull(), 0)\n",
    "      df[f'{col} cumulatief'] = df[f'{col} week'].cumsum().fillna(0)\n",
    "      df[f'{col} week -1'] = df[f'{col} cumulatief'].shift(1).fillna(0)\n",
    "      df[f'{col} week'] = df[f'{col} week'].fillna(0)\n",
    "\n",
    "    df.index.rename('Key', inplace=True)\n",
    "    df = df[[col for col in df.columns if col != 'Land']]\n",
    "    regioposten.append(df.reset_index())\n",
    "  regioposten = pd.concat(regioposten, axis=0)\n",
    "  regioposten['Datum'] = regioposten['Datum'].dt.strftime('%Y-%m-%d')\n",
    "  regioposten.rename(columns={'GGDregio': 'GGD regio'}, inplace=True)\n",
    "  display(regioposten[['Code', 'Naam', 'Datum']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-bryan",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "await publish(regioposten, 'Regioposten')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.747225,
   "end_time": "2021-02-25T09:54:07.741631",
   "environment_variables": {},
   "exception": true,
   "input_path": "-",
   "output_path": "Regio.ipynb",
   "parameters": {},
   "start_time": "2021-02-25T09:53:34.994406",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}